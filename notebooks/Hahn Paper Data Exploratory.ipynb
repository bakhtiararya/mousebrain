{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d22fae3c-de8b-48fa-8986-7d2c826e2281",
   "metadata": {},
   "source": [
    "# Hahn Paper Data Exploratory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85e0ce36",
   "metadata": {},
   "source": [
    "The following code is executed after convering the .rds file into several files. Please see **\"Replicating Data Processing for Hanh .rds File.pdf\"** file for more information. Here, we import all of the converted data files and construct anndata to use for scanpy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c57fe06-8dae-43ba-bb1f-cf4d4b7bf393",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scanpy as sc\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import os\n",
    "import math\n",
    "import anndata as ad\n",
    "import pandas as pd\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3859b6f-7d7e-4ab3-bd08-af638658be33",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PDF(object):\n",
    "  def __init__(self, pdf, size=(200,200)):\n",
    "    self.pdf = pdf\n",
    "    self.size = size\n",
    "  def _repr_html_(self):\n",
    "    return '<iframe src={0} width={1[0]} height={1[1]}></iframe>'.format(self.pdf, self.size)\n",
    "  def _repr_latex_(self):\n",
    "    return r'\\includegraphics[width=1.0\\textwidth]{{{0}}}'.format(self.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce2c4f9-53a5-4971-8d14-e868479430d1",
   "metadata": {},
   "source": [
    "## Paper: A spatiotemporal map of the aging mouse brain reveals white matter tracts as vulnerable foci"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c040a29b-0f6a-4558-877c-ee426d7dbaf1",
   "metadata": {},
   "source": [
    "https://www.biorxiv.org/content/10.1101/2023.03.10.531984v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c06fa26d-6fb9-4973-8f39-9e12611aeb6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "PDF('2022.09.18.508419v2.full.pdf',size=(1300,1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e037297a-5b0d-4850-af15-f41be0bd1cd3",
   "metadata": {},
   "source": [
    "## Oliver Hahn's email Replies Regarding the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a2b97e8-5d15-45dc-b727-c943313eff0b",
   "metadata": {},
   "source": [
    "Regarding labeling: this was done pretty simply by hand (aka, me). I harmonized the transcriptome spots from all samples and then tried to annotate \n",
    "the resulting clusters by hand based on anatomy, marker genes, etc.\n",
    "\n",
    "I’m not sure I would use that as ‘ground truth’ - I did it to the best of my abilities and so that the annotations are compatible with my bulk-seq data, \n",
    "and I think in that regard, it worked. But I would prefer to not have that being used as some sort of ’state of the art’ reference to which you contrast any \n",
    "computational method that you are setting up (and show that yours work a lot better ;) this was done in a very, very conservative way - and I might have \n",
    "preferred something more sophisticated - to not have reader/reviewers be distracted from the main narrative, which was dealing with the effects of aging. \n",
    "\n",
    "\n",
    "\n",
    "It contains a single RDS object, which you can load into R via loadRDS(“FILEPATH.rds”) -> SpatialData\n",
    "\n",
    "All things considered, I decided to just pass you a cleaned R object that contains all the relevant count matrices (including normalizations), \n",
    "mapping locations, various forms of dimensionality reduction, clustering, metadata and spatial images. I assume you probably work more with python \n",
    "but I guess you’ll manage to extract what you need from that, and it’s a more compact format than multiple txt files, some images etc. \n",
    "This object was generated with the Seurat package, and a couple of relevant commands and ways to interact with the data \n",
    "(and extract whatever you need for your python or other environment) you’ll find in there. \n",
    "Please let me know once you downloaded the data, so that I can close the folder again.\n",
    "\n",
    "The metadata contains two sets of region annotations: a ‘cluster-level’ and a ‘region-level’. \n",
    "    - In case of the former, we just looked at the transcriptional clusters and tried to annotate these one by one, often matching known substructures of the Allen Brain atlas. \n",
    "    - In the region-level  annotation, we grouped these together where we considered it ‘meaningful’. \n",
    "You’ll find a bit more explanation, and what clusters were combined into regions, in the attached copy of our respective figure.\n",
    "\n",
    "One more thing: as you can probably see/imagine, we tried very hard to align the individual tissue slices as good as possible. That is, trying to \n",
    "cut at the same depth. We were less interested in analyzing what regions/clusters do we capture - that is kinda boring to us and people like the \n",
    "Allen Atlas have already done that - but rather what changes at the same location/region if you go from a young to an old brain.\n",
    "\n",
    "Since region-identity has so much stronger transcriptional variance than aging (in some analyses it’s 40% of variance explained by region vs. 0.5% for aging), \n",
    "we had to be sure we’d not end up comparing apples with oranges by not cutting at the correct depth. However, since we had to do that literally by eye&hand, \n",
    "there’s an inevitable degree of variation present (you can see that in Young Sample 1). Just be mindful about that, as it could influence your analysis.\n",
    "\n",
    "I hope all is clear and you’ll be able to navigate through the data from here on. Keep me in the loop, I’d be genuinely interested what you can dig out. \n",
    "The dataset is as of now massively under-explored, which was a concession I just had to make in order to get the paper out. However, as I’m moving to Calico \n",
    "this summer to start my own lab, I might revisit some of these things. There are always opportunities to collaborate and exchange ideas.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e06ba3c-8c93-4dbf-87b3-6c7d90bc0507",
   "metadata": {},
   "source": [
    "**Figure S5 Robust capture of spatial transcriptomes across age**\n",
    "\n",
    "(A) Spatial-seq processing and analysis overview. Whole brains were frozen prior to OCT embedding and cryo-sectioning. Coronal sections were placed on a 10X Visium Spatial Gene Expression slide, followed by H&E staining and spatial reverse-transcription reaction. Single-spot transcriptomes were integrated, clustered with default settings and visualized as UMAP. Clustered spatial spot transcriptomes were mapped to their original location. To annotate the clusters, their marker genes (Table S6) were visualized, compared to the Allen Brain Atlas (23). (B) Complete data description and abbreviations of ontology and nomenclature for spatial transcriptome data. Regional-level annotated manually, and cluster-level determined by Seurat clustering. (C,D) Representative spatial transcriptome data (6 months replicate #2), colored by cluster-level annotation and represented as (C) UMAP and (D) spatial transcriptome. (E,F) Representative spatial transcriptome data (6 months replicate #2), colored by region-level annotation and represented as (E) UMAP and (F) spatial transcriptome. (G,H,I) Cluster-level annotation across replicates and datasets represented as (G) UMAP and (H) spatial transcriptome. (I) Fraction of spots corresponding to each cluster. (J,K,L) Region-level annotation across replicates and datasets represented as (J) UMAP and (K) spatial transcriptome. (L) Fraction of spots corresponding to each region."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c7c1af1-4bde-479e-ac58-9205d607d75a",
   "metadata": {},
   "outputs": [],
   "source": [
    "PDF('FigS5.pdf',size=(1300,1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b471c109-77a4-4453-8ebb-fa973437aad9",
   "metadata": {},
   "source": [
    "## Some Information of Original .rds Data file in RStudio"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2bc89d62-6de6-4708-a6da-c930a6b9377a",
   "metadata": {},
   "source": [
    "> mydata <- readRDS(\"Visium_AgingCohort_Coronale.rds\")\n",
    "> mydata\n",
    "An object of class Seurat \n",
    "55316 features across 16277 samples within 3 assays \n",
    "Active assay: SCT (21031 features, 3000 variable features)\n",
    " 2 other assays present: Spatial, integrated\n",
    " 3 dimensional reductions calculated: pca, tsne, umap\n",
    " 6 images present: slice1, slice1.1.1, slice1.2.2, slice1.3.3, slice1.4.4, slice1.5.5"
   ]
  },
  {
   "cell_type": "raw",
   "id": "da027177-2412-4b2d-869b-3a2e9cbe15f1",
   "metadata": {},
   "source": [
    "mydata@images\n",
    "$slice1\n",
    "Spatial data from the VisiumV1 technology for 2492 samples\n",
    "Associated assay: Spatial \n",
    "Image key: slice1_ \n",
    "\n",
    "$slice1.1.1\n",
    "Spatial data from the VisiumV1 technology for 2657 samples\n",
    "Associated assay: Spatial \n",
    "Image key: slice1_ \n",
    "\n",
    "$slice1.2.2\n",
    "Spatial data from the VisiumV1 technology for 2889 samples\n",
    "Associated assay: Spatial \n",
    "Image key: slice1_ \n",
    "\n",
    "$slice1.3.3\n",
    "Spatial data from the VisiumV1 technology for 2743 samples\n",
    "Associated assay: Spatial \n",
    "Image key: slice1_ \n",
    "\n",
    "$slice1.4.4\n",
    "Spatial data from the VisiumV1 technology for 2729 samples\n",
    "Associated assay: Spatial \n",
    "Image key: slice1_ \n",
    "\n",
    "$slice1.5.5\n",
    "Spatial data from the VisiumV1 technology for 2767 samples\n",
    "Associated assay: Spatial \n",
    "Image key: slice1_ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "379590df-37f6-4e50-b1ec-4dc0fa63cb7d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Loading .rds's meta.data file from Exported CSV file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d584719-6ded-43b1-9d0f-85ef30969ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "seurat_metadata_df = pd.read_csv(\"seurat_metadata.csv\")\n",
    "seurat_metadata_df = seurat_metadata_df.rename(columns={\"Unnamed: 0\": \"Cell\"})\n",
    "seurat_metadata_df = seurat_metadata_df.set_index(\"Cell\")\n",
    "seurat_metadata_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55670544-a93f-4525-9159-76d07b3ec23f",
   "metadata": {},
   "source": [
    "## Loading .rds's image tissue slices from Exported CSV files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e26546ee-d134-4999-a3a9-861b3499161f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all the tissue image slice files\n",
    "tissue_coordinates_slice1_df = pd.read_csv(\"tissue_coordinates_slices/tissue_coordinates_slice1.csv\")\n",
    "tissue_coordinates_slice1_df[\"slice\"] = \"slice1\"\n",
    "\n",
    "tissue_coordinates_slice1_1_1_df = pd.read_csv(\"tissue_coordinates_slices/tissue_coordinates_slice1_1_1.csv\")\n",
    "tissue_coordinates_slice1_1_1_df[\"slice\"] = \"slice1_1_1\"\n",
    "\n",
    "tissue_coordinates_slice1_2_2_df = pd.read_csv(\"tissue_coordinates_slices/tissue_coordinates_slice1_2_2.csv\")\n",
    "tissue_coordinates_slice1_2_2_df[\"slice\"] = \"slice1_2_2\"\n",
    "\n",
    "tissue_coordinates_slice1_3_3_df = pd.read_csv(\"tissue_coordinates_slices/tissue_coordinates_slice1_3_3.csv\")\n",
    "tissue_coordinates_slice1_3_3_df[\"slice\"] = \"slice1_3_3\"\n",
    "\n",
    "tissue_coordinates_slice1_4_4_df = pd.read_csv(\"tissue_coordinates_slices/tissue_coordinates_slice1_4_4.csv\")\n",
    "tissue_coordinates_slice1_4_4_df[\"slice\"] = \"slice1_4_4\"\n",
    "\n",
    "tissue_coordinates_slice1_5_5_df = pd.read_csv(\"tissue_coordinates_slices/tissue_coordinates_slice1_5_5.csv\")\n",
    "tissue_coordinates_slice1_5_5_df[\"slice\"] = \"slice1_5_5\"\n",
    "\n",
    "# concatenate the all the tissue slice DataFrames\n",
    "slice_list = [tissue_coordinates_slice1_df, tissue_coordinates_slice1_1_1_df, tissue_coordinates_slice1_2_2_df, \n",
    "              tissue_coordinates_slice1_3_3_df, tissue_coordinates_slice1_4_4_df, tissue_coordinates_slice1_5_5_df]\n",
    "tissue_coordinates_all_slices = pd.concat(slice_list)\n",
    "tissue_coordinates_all_slices = tissue_coordinates_all_slices.rename(columns={\"Unnamed: 0\": \"Cell\"})\n",
    "tissue_coordinates_all_slices = tissue_coordinates_all_slices.set_index(\"Cell\")\n",
    "\n",
    "tissue_coordinates_all_slices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82d182a5-2e2a-4e52-a66e-94a2a2bfc916",
   "metadata": {},
   "source": [
    "## Concatentate the Seurat Metadata DataFrame with the Tissue Coordinate DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "396834d1-39c8-4406-b2c6-8127ea9728f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "seurat_full_metadata_df = pd.concat([seurat_metadata_df, tissue_coordinates_all_slices], axis=1)\n",
    "\n",
    "# Create new columns for rotated coordinates\n",
    "rotated_coord = np.rot90(np.rot90(np.array(seurat_full_metadata_df[['imagerow', 'imagecol']])))\n",
    "seurat_full_metadata_df['imagerow_rotated_v2'] = rotated_coord[:, 0]\n",
    "seurat_full_metadata_df['imagecol_rotated_v2'] = rotated_coord[:, 1]\n",
    "\n",
    "seurat_full_metadata_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e473546-32cb-4f5a-a81a-67e81b03b17d",
   "metadata": {},
   "outputs": [],
   "source": [
    "slice1_data_df = seurat_full_metadata_df[seurat_full_metadata_df[\"slice\"]==\"slice1_3_3\"]\n",
    "slice1_age_data_df = slice1_data_df[slice1_data_df[\"age\"]==\"M6\"]\n",
    "slice1_age_data_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d177d42-1311-4b98-988f-a4986ab85650",
   "metadata": {},
   "source": [
    "## Assay CSV Files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c51f1df",
   "metadata": {},
   "source": [
    "Amongst the assay data available, we are opening the SCT and Spatial Assay for the \"data\" (normalized) information presented"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b751abbd-0bea-4ce4-9956-23ee96216be1",
   "metadata": {},
   "source": [
    "### SCT Assay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8818d97-5f9c-483a-8bd4-c9c06dcfea23",
   "metadata": {},
   "outputs": [],
   "source": [
    "sct_data_assay_df = pd.read_csv(\"assays/sct_data_assay.csv\")\n",
    "sct_data_assay_df = sct_data_assay_df.rename(columns={\"Unnamed: 0\": \"Gene\"})\n",
    "sct_data_assay_df = sct_data_assay_df.set_index(\"Gene\")\n",
    "sct_data_assay_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afebb832-af9f-498f-8529-cf7990102826",
   "metadata": {},
   "outputs": [],
   "source": [
    "sct_data_assay_df.loc[(sct_data_assay_df!=0).any(axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "870a7b0d-bace-40bf-a325-be671c89ee6d",
   "metadata": {},
   "source": [
    "### Spatial Assay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "562df7d4-6d14-44fa-b78b-9686552491b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "spatial_data_assay_df = pd.read_csv(\"assays/spatial_data_assay.csv\")\n",
    "spatial_data_assay_df = spatial_data_assay_df.rename(columns={\"Unnamed: 0\": \"Gene\"})\n",
    "spatial_data_assay_df = spatial_data_assay_df.set_index(\"Gene\")\n",
    "print(\"Number of Genes in Spatial Assay:\", len(spatial_data_assay_df))\n",
    "print(\"Number of Cells in Spatial Assay:\", len(spatial_data_assay_df.columns))\n",
    "display(spatial_data_assay_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c06a3f-c17a-4432-a1d5-3638d23f5e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(spatial_data_assay_df.loc['AC234645.1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18017dc7-1bb4-43d4-bdfe-faf04d5cd691",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out genes that have expression level 0 across all cells\n",
    "\n",
    "spatial_data_assay_df = spatial_data_assay_df.loc[spatial_data_assay_df.any(axis=1)]\n",
    "print(\"Number of Genes in Spatial Assay:\", len(spatial_data_assay_df))\n",
    "print(\"Number of Cells in Spatial Assay:\", len(spatial_data_assay_df.columns))\n",
    "display(spatial_data_assay_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bbdddae-13b4-42d0-afd2-0d8b5a9d19ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "32285-23923"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56d2c2be",
   "metadata": {},
   "source": [
    "## Loading Raw Image Slices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "485326c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CSV file into a DataFrame\n",
    "raw_image_slice1_df = pd.read_csv('raw_image_slices/raw_image_slice1.csv', index_col=0)\n",
    "raw_image_slice1_1_1_df = pd.read_csv('raw_image_slices/raw_image_slice1_1_1.csv', index_col=0)\n",
    "raw_image_slice1_2_2_df = pd.read_csv('raw_image_slices/raw_image_slice1_2_2.csv', index_col=0)\n",
    "raw_image_slice1_3_3_df = pd.read_csv('raw_image_slices/raw_image_slice1_3_3.csv', index_col=0)\n",
    "raw_image_slice1_4_4_df = pd.read_csv('raw_image_slices/raw_image_slice1_4_4.csv', index_col=0)\n",
    "raw_image_slice1_5_5_df = pd.read_csv('raw_image_slices/raw_image_slice1_5_5.csv', index_col=0)\n",
    "\n",
    "# Convert the DataFrame into a NumPy array\n",
    "raw_image_slice1_data = raw_image_slice1_df.values\n",
    "raw_image_slice1_1_1_data = raw_image_slice1_1_1_df.values\n",
    "raw_image_slice1_2_2_data = raw_image_slice1_2_2_df.values\n",
    "raw_image_slice1_3_3_data = raw_image_slice1_3_3_df.values\n",
    "raw_image_slice1_4_4_data = raw_image_slice1_4_4_df.values\n",
    "raw_image_slice1_5_5_data = raw_image_slice1_5_5_df.values\n",
    "\n",
    "raw_image_slice1_1_1_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e35e1358-cde1-4519-aa3c-472d6bd29d56",
   "metadata": {},
   "source": [
    "## Building AnnData for Scanpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1204a58-e573-4fed-b35f-a203ea2e5fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://anndata.readthedocs.io/en/latest/generated/anndata.AnnData.html\n",
    "\n",
    "import hdf5plugin\n",
    "\n",
    "#assays = [\"spatial\", \"sct\"]\n",
    "assays = [\"spatial\"]\n",
    "\n",
    "for assay in assays:\n",
    "\n",
    "    if assay == \"spatial\":\n",
    "        assay_data_df = spatial_data_assay_df.copy()\n",
    "    else:\n",
    "        assay_data_df = sct_data_assay_df.copy()\n",
    "    \n",
    "    # transpose the assay data to use as 'X' matrix for the anndata\n",
    "    temp_transposed_assay_data_df = assay_data_df.copy().T.reset_index()\n",
    "    transposed_assay_data_df = pd.DataFrame(temp_transposed_assay_data_df.values)\n",
    "    transposed_assay_data_df.columns = [\"Cell\"] + list(temp_transposed_assay_data_df.columns[1:])\n",
    "    transposed_assay_data_df = transposed_assay_data_df.set_index(\"Cell\")\n",
    "\n",
    "    # Construct AnnData\n",
    "    adata_build = ad.AnnData(X=transposed_assay_data_df.values.astype(np.float64))\n",
    "\n",
    "    # copy Metadata to AnnData Object\n",
    "    adata_build.obs = seurat_full_metadata_df\n",
    "    \n",
    "    # copy gene names for .var \n",
    "    adata_build.var = pd.DataFrame(transposed_assay_data_df.columns).rename(columns={0: 'Gene'}).set_index(\"Gene\")\n",
    "\n",
    "    # copy all Spatial information to AnnData Object (all image files are associated with \"Spatial\" assay)\n",
    "    adata_build.obsm[\"X_spatial\"] = np.array(adata_build.obs[[\"imagerow\", \"imagecol\"]])\n",
    "    adata_build.obsm[\"spatial\"] = np.array(adata_build.obs[[\"imagerow\", \"imagecol\"]])\n",
    "    adata_build.obsm[\"X_spatial_rotated\"] = np.array(adata_build.obs[[\"imagerow_rotated_v2\", \"imagecol_rotated_v2\"]])\n",
    "    adata_build.obsm[\"spatial_rotated\"] = np.array(adata_build.obs[[\"imagerow_rotated_v2\", \"imagecol_rotated_v2\"]])\n",
    "    \n",
    "    # placing slice image data in 'uns' (this is an extra, last resort place to put the data for the AnnData)\n",
    "    adata_build.uns[\"spatial\"] = {}\n",
    "    adata_build.uns[\"spatial\"][\"assay_slice_images\"] = {}\n",
    "    adata_build.uns[\"spatial\"][\"assay_slice_images\"][\"images\"] = {}\n",
    "    adata_build.uns[\"spatial\"][\"assay_slice_images\"][\"images\"][\"slice1\"] = raw_image_slice1_data\n",
    "    adata_build.uns[\"spatial\"][\"assay_slice_images\"][\"images\"] [\"slice1_1_1\"] = raw_image_slice1_1_1_data\n",
    "    adata_build.uns[\"spatial\"][\"assay_slice_images\"][\"images\"] [\"slice1_2_2\"] = raw_image_slice1_2_2_data\n",
    "    adata_build.uns[\"spatial\"][\"assay_slice_images\"][\"images\"] [\"slice1_3_3\"] = raw_image_slice1_3_3_data\n",
    "    adata_build.uns[\"spatial\"][\"assay_slice_images\"][\"images\"] [\"slice1_4_4\"] = raw_image_slice1_4_4_data\n",
    "    adata_build.uns[\"spatial\"][\"assay_slice_images\"][\"images\"] [\"slice1_5_5\"] = raw_image_slice1_5_5_data\n",
    "\n",
    "    # for visualizations associated with regionLevel\n",
    "    category_colors = {\n",
    "        'Cortex': np.array([0.416, 0.0, 0.416, 1.0]),                                 # purple\n",
    "        'Hypothalamus': np.array([0.0, 0.502, 0.0, 1.0]),                             # green\n",
    "        'Amygdala': np.array([1.0, 0.80, 0.0, 1.0]),                                  # yellow\n",
    "        'Thalamus': np.array([0.0, 0.0, 0.502, 1.0]),                                 # dark blue\n",
    "        'Striatum': np.array([1.0, 0.714, 0.757, 1.0]),                               # light pink\n",
    "        'White matter': np.array([1.0, 0.0, 0.0, 1.0]),                               # red\n",
    "        'Cortical subplate': np.array([0.502, 0.502, 0.502, 1.0]),                    # grey\n",
    "        'Globus pallidus': np.array([0.322, 0.651, 0.839, 1.0]),                      # light blue\n",
    "        'Hippocampus': np.array([1.0, 0.502, 0.0, 1.0]),                              # orange\n",
    "        'Ventricle': np.array([0.824, 0.706, 0.549, 1.0]),                            # tan\n",
    "        'Thalamic reticular nucleus': np.array([0.565, 0.933, 0.560, 1.0]),           # light green\n",
    "        'Basolateral amygdalar nucleus': np.array([1, 0.07843137, 0.57647059, 1.0]),  # dark pink\n",
    "        'Choroid Plexus': np.array([0.0, 0.0, 0.0, 1.0]),                             # black\n",
    "    }\n",
    "\n",
    "    adata_build.uns[\"regionLevel_colors\"] = category_colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b5d794-067d-48c5-9171-5c46cf0b6707",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "494d5c7f-8a80-4e87-b5c4-d1121ffbf754",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_build.write_h5ad(\"hahn_spatial_assay_anndata\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d9669a3-ccf7-4bdb-bc39-b011d23d072a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a6a545-cb34-4cb0-8eaa-727b2e800da3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "135d60b2-fbb4-40f9-883c-3c974eda57b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3bad5b7-fe96-41ed-a994-4ba71d1b14fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "if assay == \"spatial\":\n",
    "    adata_build.write_h5ad(\"hahn_spatial_assay_anndata\", compression=hdf5plugin.FILTERS[\"zstd\"])\n",
    "else:\n",
    "    adata_build.write_h5ad(\"hahn_sct_assay_anndata\", compression=hdf5plugin.FILTERS[\"zstd\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac5dab15-a353-4319-9d42-cff38cec371d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f7b7e2-4c3e-442f-8f81-78887e7f6a02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "687fcba8-8ebe-45a7-9d63-e684efa8f7ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f86fca2-a683-413c-b449-af5f4dc538d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eab20c71-7cfb-4db8-b485-dce08329781c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
